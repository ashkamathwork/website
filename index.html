<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Aishwarya Kamath</title>
  <style>
    body { margin:0; background:#000; color:#e0f7ff; font-family:Helvetica, sans-serif; scroll-behavior: smooth; }
    nav { position:fixed; top:0; width:100%; background:rgba(0,0,0,0.8); display:flex; justify-content:center; padding:1rem; z-index:1000; }
    nav a { margin:0 1rem; color:#90dffe; text-decoration:none; }
    section { padding:100px 20px; max-width:800px; margin:auto; }
    h1 { font-size:3rem; margin-bottom:0.5rem; }
    h2 { color:#90dffe; margin-top:2rem; }
    a.link { color:#b3e9ff; }
    img.profile { width:150px; border-radius:50%; margin-top:1.5rem; display: block; margin-left: auto; margin-right: auto; }
  </style>
</head>
<body>
  <nav>
    <a href="#home">Home</a>
    <a href="#about">About</a>
    <a href="#research">Research</a>
    <a href="#videos">Videos</a>
    <a href="#contact">Contact</a>
  </nav>
    <a href="#contact">Contact</a>
  </nav>

  <section id="home">
    <h1>Aishwarya Kamath</h1>
    <h2>Senior Research Scientist, Google DeepMind</h2>
    <p>Exploring intelligence through language, vision, and learning.</p>
    <img src="aishwarya.jpg" alt="Aishwarya Kamath" class="profile">
  </section>

  <section id="about">
    <h2>About</h2>
    <p>I am a Senior Research Scientist at Google DeepMind, contributing to the development of the next generation of AI models on the Gemini and Gemma teams. Most recently, I have had the pleasure of leading the multi-modal efforts on Gemma 3, a state-of-the art vision and language model that is open source! I have also been working on the Gemini team since December 2023, improving the spatial understanding capabilities of Gemini.</p>
    <p>Previously, I earned my PhD on Fine-Grained Vision and Language Understanding at New York University's Center for Data Science advised by Prof. Yann LeCun and Prof. Kyunghyun Cho, and a Masters at University of Massachusetts Amherst advised by Prof. Andrew McCallum.</p>
  </section>

  <section id="research">
  <h2>Recent Research Highlights</h2>
  <ul style="list-style-type: disc; padding-left: 1.2rem; margin-bottom: 2rem;">
    <li><strong><a class="link" href="https://arxiv.org/abs/2503.19786">Gemma 3</a></strong>: Gemma 3 Technical Report</li>
    <li><strong><a class="link" href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf">Gemini 2.5</a></strong>: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.</li>
    <li><strong><a class="link" href="https://arxiv.org/abs/2403.05530">Gemini 1.5</a></strong>: Unlocking multimodal understanding across millions of tokens of context</li>
  </ul>
</section>

  <section id="videos">
    <h2>Talks & Videos</h2>
    <ul>
      <li><a class="link" href="https://youtu.be/FagNt06rSBk?feature=shared&t=816">5 minute deep-dive on Gemma 3 at Dev Day March 2025</a></li>
      <li><a class="link" href="https://www.youtube.com/watch?v=fys-Rr6eoKo">Demo-ing Gemma 3 vision capabiltiies : Build a travel companion!</a></li>
    </ul>
  

    <h2>Contact</h2>
    <p>Email: firstnamelastname20@gmail.com </p>
    <p>
      <a class="link" href="https://scholar.google.com/citations?user=WaW2C0UAAAAJ&hl=en">Google Scholar</a> |
      <a class="link" href="https://twitter.com/ashkamath20">Twitter</a>
    </p>
  </section>
</body>
</html>

